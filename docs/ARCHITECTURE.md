# StructForge AI - 架构设计方案

## 一、项目定位

**StructForge AI** 是一个**通用、智能、自适应的**数据配置文件工作流系统，通过AI自主分析，无需预设模板即可处理各类文件格式和数据结构。

## 二、核心设计理念

### 2.1 自主分析优先
- **无需预设模板**：AI自动分析文件结构、字段含义、数据关系
- **通用适配**：支持任意格式（XML、JSON、YAML、CSV、Excel、TSV等）
- **智能推断**：自动识别数据类型、约束、关联关系

### 2.2 RTX 4060 优化
- **本地部署**：完全离线，保护数据隐私
- **GPU加速**：充分利用8GB VRAM进行推理
- **模型选择**：7B-13B量化模型，平衡性能与准确性
  - Qwen2.5-7B（推荐，中文支持好）
  - Llama3.1-8B（英文场景）
  - Mistral-7B（通用性强）

### 2.3 工作流架构

```
文件上传 → AI结构分析 → Schema生成 → 自然语言编辑 → 数据操作 → 格式导出
    ↓           ↓            ↓            ↓            ↓           ↓
  格式检测   字段推断     关系图谱      意图理解      智能修改   多格式输出
```

## 三、技术架构

### 3.1 整体架构

```
┌─────────────────────────────────────────────────────────┐
│                   前端层 (React + TS)                     │
│  文件管理 | 数据可视化 | 自然语言编辑 | 关系图谱           │
└────────────────────┬────────────────────────────────────┘
                     │ REST API
┌────────────────────▼────────────────────────────────────┐
│                 API层 (FastAPI)                          │
│  文件管理API | Schema API | 编辑API | 导出API            │
└─────┬────────────┬──────────────┬──────────────┬────────┘
      │            │              │              │
┌─────▼──────┐ ┌───▼─────────┐ ┌─▼──────────┐ ┌▼──────────┐
│ 文件解析层  │ │ Schema学习层 │ │ AI理解层    │ │ 工作流引擎 │
│ Parser     │ │ Learner     │ │ LLM Client │ │ Engine    │
│ - XML/JSON │ │ - 结构推断   │ │ - 意图理解  │ │ - 流程编排 │
│ - CSV/Excel│ │ - 关系分析   │ │ - 操作生成  │ │ - 版本管理 │
│ - YAML/TSV │ │ - 约束推断   │ │ - 验证建议  │ │ - 历史回溯 │
└────────────┘ └─────────────┘ └────────────┘ └───────────┘
                     │
┌────────────────────▼────────────────────────────────────┐
│              AI模型层 (本地部署)                          │
│  - Ollama / LM Studio (模型管理)                        │
│  - Qwen2.5-7B / Llama3.1-8B (推理)                      │
│  - Sentence Transformers (嵌入)                         │
│  - FAISS / ChromaDB (向量检索)                          │
└─────────────────────────────────────────────────────────┘
```

### 3.2 核心模块设计

#### 3.2.1 文件解析层（增强版）

**目标**：支持所有常见数据格式

- **结构化格式**：XML、JSON、YAML
- **表格格式**：CSV、TSV、Excel (.xlsx, .xls)
- **其他格式**：INI、Properties、TOML

**设计特点**：
- 统一接口 `BaseParser`
- 自动格式检测
- 保持原始结构信息
- 支持大文件流式处理

#### 3.2.2 Schema学习层（AI驱动）

**目标**：AI自主分析数据结构

**核心功能**：
1. **结构推断**
   - 自动识别嵌套层级
   - 检测重复模式和数组
   - 识别键值对和表格结构

2. **语义理解**
   - 字段命名推断（通过AI）
   - 数据类型自动分类
   - 约束条件识别（范围、枚举等）

3. **关系分析**
   - 引用关系（ID → 实体）
   - 依赖关系（A字段依赖于B字段）
   - 组合关系（整体-部分）

**实现策略**：
- 先用规则引擎快速分析基础结构
- 再用AI模型深度理解语义
- 使用向量库存储历史Schema，加速相似结构匹配

#### 3.2.3 AI理解层（RTX 4060优化）

**模型选择**（针对RTX 4060 8GB VRAM）：
- **主要模型**：Qwen2.5-7B-Instruct（Q4量化）
  - 中文理解优秀
  - 量化后约4.5GB VRAM
  - 推理速度：15-30 tokens/s

- **备选模型**：
  - Llama3.1-8B（Q4量化，英文场景）
  - Mistral-7B（通用场景）

**推理优化**：
- 使用 `vLLM` 或 `Ollama` 的GPU加速
- 批处理优化（多文件并行分析）
- KV Cache优化
- 量化方案：Q4_K_M（平衡精度与速度）

**功能模块**：
1. **自然语言理解**
   - 解析用户指令
   - 提取操作意图（增删改查）
   - 识别目标字段和数值

2. **智能操作生成**
   - 根据Schema生成操作步骤
   - 自动验证约束
   - 提供修改建议

3. **上下文学习**
   - 从历史操作中学习
   - 建立项目特定的理解模型

#### 3.2.4 工作流引擎

**功能**：
- 流程编排（导入 → 分析 → 编辑 → 导出）
- 版本管理（Git-like）
- 历史回溯
- 批量处理
- 插件系统（扩展支持）

## 四、RTX 4060部署方案

### 4.1 环境要求

```
- GPU: NVIDIA RTX 4060 (8GB VRAM)
- RAM: 16GB+ 推荐
- 驱动: CUDA 11.8+
- Python: 3.10+
```

### 4.2 模型部署

**方案A：Ollama（推荐，简单）**
```bash
# 安装Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 下载模型
ollama pull qwen2.5:7b-instruct-q4
ollama pull llama3.1:8b-instruct-q4

# 启动服务
ollama serve
```

**方案B：LM Studio（图形界面）**
- 下载LM Studio
- 选择模型并加载
- 启动本地API服务器

**方案C：vLLM（高性能，需要配置）**
```bash
pip install vllm
vllm serve qwen/Qwen2.5-7B-Instruct --quantization awq
```

### 4.3 性能优化

1. **模型量化**：使用Q4量化，VRAM占用降低50%
2. **批处理**：合并多个请求，提高吞吐量
3. **缓存策略**：缓存常见Schema分析结果
4. **异步处理**：大文件分析异步化，不阻塞主线程

## 五、文件格式支持扩展

### 5.1 新增格式

**CSV解析器**
- 自动检测分隔符（逗号、分号、制表符）
- 自动推断数据类型
- 处理引号和转义字符
- 支持大文件流式读取

**Excel解析器**
- 支持.xlsx和.xls
- 多Sheet处理
- 合并单元格识别
- 公式值提取

**INI/Properties解析器**
- 键值对解析
- Section分组
- 注释保留

### 5.2 AI自主格式识别

**策略**：
1. 先通过文件扩展名和MIME类型初步判断
2. 读取文件头部内容
3. 使用AI分析内容特征
4. 自动选择最佳解析器

## 六、实施路径

### 阶段1：基础架构（2周）
- [x] 项目结构搭建
- [ ] 文件解析层（XML/JSON/YAML/CSV/Excel）
- [ ] 基础API框架
- [ ] 前端基础UI

### 阶段2：AI集成（3周）
- [ ] Ollama集成
- [ ] Schema学习器（规则+AI混合）
- [ ] 自然语言理解模块
- [ ] 向量数据库集成

### 阶段3：智能分析（2周）
- [ ] AI自主文件分析
- [ ] Schema自动推断
- [ ] 关系图谱生成
- [ ] 智能编辑建议

### 阶段4：完整工作流（2周）
- [ ] 工作流引擎
- [ ] 版本管理
- [ ] 多格式导出
- [ ] 批量处理

### 阶段5：优化与测试（1周）
- [ ] 性能优化
- [ ] 错误处理完善
- [ ] 用户体验优化
- [ ] 文档编写

## 七、关键技术决策

### 7.1 为什么选择本地AI？
- **隐私保护**：配置数据不离开本地
- **成本控制**：无API调用费用
- **响应速度**：本地推理延迟低
- **离线可用**：不依赖网络

### 7.2 为什么选择7B模型？
- RTX 4060的最佳平衡点
- 足够理解复杂数据结构
- 推理速度可接受（15-30 tokens/s）
- 量化后VRAM占用可控

### 7.3 为什么需要向量数据库？
- 快速匹配相似Schema（避免重复AI分析）
- 积累知识库（项目特定模式学习）
- 加速相似文件处理

## 八、预期性能指标

- **文件解析速度**：< 1秒（10MB以下）
- **Schema分析速度**：2-5秒（AI推理）
- **自然语言响应**：1-3秒
- **模型加载时间**：5-10秒（首次）
- **内存占用**：< 12GB（含模型）
- **VRAM占用**：< 6GB（模型推理）

