---
alwaysApply: true
---

# StructForge AI - 项目开发规则

## 一、项目定位

StructForge AI 是一个**通用、智能、自适应的**数据配置文件工作流系统，通过AI自主分析，无需预设模板即可处理各类文件格式和数据结构。

## 二、目录结构规范

### 2.1 项目根目录

项目根目录为：`F:\StructForgeAI`

```
F:\StructForgeAI\
├── backend/              # 后端服务（Python FastAPI）
├── frontend/             # 前端应用（React + TypeScript，待开发）
├── docs/                 # 项目文档
├── data/                 # 数据目录（不提交到Git）
│   ├── uploads/         # 上传文件
│   ├── exports/         # 导出文件
│   ├── vector_db/       # 向量数据库文件
│   └── structforge.db   # SQLite数据库
├── templates/           # 模板文件
├── logs/                # 日志文件（不提交到Git）
├── tests/               # 测试文件
├── tools/               # 工具脚本
└── README.md            # 项目说明
```

### 2.2 后端目录结构

```
backend/
├── api/                 # API路由层
│   ├── __init__.py     # 路由聚合
│   ├── base.py         # API基类和工具函数
│   ├── files.py        # 文件管理API
│   ├── schemas.py      # Schema分析API
│   ├── workflows.py    # 工作流API
│   ├── ai.py           # AI服务API
│   ├── data_operations.py # 数据操作API
│   └── ai_workflow.py  # AI工作流API
├── storage/             # 存储层（可插拔存储后端）
│   ├── __init__.py
│   ├── base.py         # 存储接口基类
│   ├── memory.py       # 内存存储
│   ├── json_storage.py # JSON文件存储
│   ├── sqlite_storage.py # SQLite存储
│   ├── sql_storage.py  # SQL数据库存储（PostgreSQL/MySQL）
│   ├── factory.py      # 存储工厂
│   └── migrate.py      # 数据迁移工具
├── core/                # 核心模块
│   ├── __init__.py
│   ├── config.py       # 配置管理
│   └── logging_config.py # 日志配置
├── data_parser/         # 文件解析层
│   ├── __init__.py
│   ├── base_parser.py  # 解析器基类
│   ├── xml_parser.py   # XML解析器
│   ├── json_parser.py  # JSON解析器
│   ├── yaml_parser.py  # YAML解析器
│   ├── csv_parser.py   # CSV/TSV解析器
│   ├── excel_parser.py # Excel解析器
│   └── parser_factory.py # 解析器工厂
├── schema_learner/      # Schema学习层
│   ├── __init__.py
│   ├── base_learner.py  # 学习器基类
│   ├── ai_learner.py   # AI学习器（LLM驱动）
│   └── rule_learner.py # 规则学习器
├── ai_integration/      # AI集成层
│   ├── __init__.py
│   ├── llm_client.py    # LLM客户端
│   ├── embedding_client.py # 嵌入向量客户端
│   └── vector_db.py    # 向量数据库
├── workflow/            # 工作流引擎
│   ├── __init__.py
│   ├── workflow_engine.py # 工作流引擎核心
│   └── default_workflows.py # 默认工作流定义
├── main.py              # 应用入口
└── requirements.txt    # Python依赖
```

### 2.3 前端目录结构

```
frontend/
├── src/
│   ├── components/     # React组件
│   │   └── Workflow/   # 工作流组件
│   │       ├── NodeConfigs/      # 节点配置组件（模块化）
│   │       │   ├── ParseFileConfig.tsx
│   │       │   ├── EditDataConfig.tsx
│   │       │   ├── FilterDataConfig.tsx
│   │       │   ├── ValidateDataConfig.tsx
│   │       │   ├── AnalyzeXMLStructureConfig.tsx
│   │       │   ├── GenerateEditorConfigConfig.tsx
│   │       │   ├── SmartEditConfig.tsx
│   │       │   ├── GenerateWorkflowConfig.tsx
│   │       │   └── index.tsx      # 配置组件注册表
│   │       ├── NodeExecutors/     # 节点执行器（模块化）
│   │       │   ├── BaseExecutor.ts
│   │       │   ├── ParseFileExecutor.ts
│   │       │   ├── EditDataExecutor.ts
│   │       │   ├── FilterDataExecutor.ts
│   │       │   ├── ValidateDataExecutor.ts
│   │       │   ├── AnalyzeXMLStructureExecutor.ts
│   │       │   ├── GenerateEditorConfigExecutor.ts
│   │       │   ├── SmartEditExecutor.ts
│   │       │   ├── GenerateWorkflowExecutor.ts
│   │       │   └── index.ts       # 执行器注册表
│   │       ├── WorkflowCanvas.tsx  # 工作流画布
│   │       ├── WorkflowNode.tsx    # 节点组件
│   │       ├── WorkflowHeader.tsx  # 工作流头部
│   │       ├── WorkflowToolbar.tsx # 工具栏
│   │       ├── NodeSelector.tsx   # 节点选择器
│   │       └── NodeDetailPanel.tsx # 节点详情面板
│   ├── pages/          # 页面组件
│   │   ├── Workflow.tsx        # 工作流列表页
│   │   └── WorkflowEditor.tsx  # 工作流编辑页
│   ├── services/       # 服务层
│   │   └── api.ts      # API客户端（统一封装）
│   ├── types/          # TypeScript类型定义
│   │   └── index.ts    # 类型导出
│   └── main.tsx        # 应用入口
```

### 2.4 目录命名规则

- **目录名**：使用 `snake_case`（小写字母+下划线）
  - ✅ 正确：`data_parser`, `schema_learner`, `ai_integration`
  - ❌ 错误：`DataParser`, `schema-learner`, `AI_Integration`

- **模块目录**：每个目录必须包含 `__init__.py` 文件

## 三、代码命名规范

### 3.1 Python 命名规则

#### 类名（Class Names）
- 使用 **PascalCase**（大驼峰）
- 类名应该清晰表达其用途
- ✅ 正确：`BaseParser`, `XMLParser`, `AISchemaLearner`, `WorkflowEngine`
- ❌ 错误：`base_parser`, `XML_Parser`, `aiSchemaLearner`

#### 函数/方法名（Function/Method Names）
- 使用 **snake_case**（小写字母+下划线）
- 函数名应该是动词或动词短语
- ✅ 正确：`parse()`, `detect_schema()`, `upload_file()`, `learn_schema()`
- ❌ 错误：`Parse()`, `detectSchema()`, `upload-file()`

#### 变量名（Variable Names）
- 使用 **snake_case**
- ✅ 正确：`file_path`, `parser`, `schema_data`, `workflow_id`
- ❌ 错误：`filePath`, `Parser`, `schema-data`

#### 常量名（Constants）
- 使用 **UPPER_CASE**（全大写下划线分隔）
- 定义在模块级别或类中
- ✅ 正确：`UPLOAD_DIR`, `AI_MODEL_PROVIDER`, `MAX_TOKENS`
- ❌ 错误：`upload_dir`, `aiModelProvider`

#### 私有成员（Private Members）
- 使用单下划线前缀 `_` 表示内部使用
- ✅ 正确：`_parse_sheet()`, `_detect_delimiter()`, `_init_faiss()`

#### 特殊方法（Magic Methods）
- 遵循Python约定：`__init__()`, `__str__()`, `__repr__()`

### 3.2 API 路由命名

- 使用 **kebab-case**（小写字母+连字符）
- ✅ 正确：`/api/v1/files/upload`, `/api/v1/schemas/infer-intent`
- ❌ 错误：`/api/v1/files/upload_file`, `/api/v1/schemas/inferIntent`

### 3.3 文件命名

- Python文件：使用 `snake_case`
  - ✅ 正确：`base_parser.py`, `xml_parser.py`, `workflow_engine.py`
  - ❌ 错误：`BaseParser.py`, `XMLParser.py`

- 配置/文档文件：
  - ✅ 正确：`README.md`, `.env.example`, `ARCHITECTURE.md`
  - 使用大写：`README.md`, `.env`

## 四、代码风格规范

### 4.1 类型提示（Type Hints）

- **必须**为所有函数参数和返回值添加类型提示
- 使用 `typing` 模块的类型：`Dict`, `List`, `Optional`, `Any`

```python
# ✅ 正确
def parse(self, file_path: Path) -> Dict[str, Any]:
    pass

def learn_schema(
    self, 
    data: Dict[str, Any], 
    metadata: Optional[Dict] = None
) -> Dict[str, Any]:
    pass

# ❌ 错误
def parse(file_path):
    pass
```

### 4.2 文档字符串（Docstrings）

- 所有公共类、方法、函数必须有docstring
- 使用Google风格或NumPy风格

```python
# ✅ 正确
def parse(self, file_path: Path) -> Dict[str, Any]:
    """
    解析文件并返回结构化数据
    
    Args:
        file_path: 文件路径
        
    Returns:
        解析后的数据结构
    """
    pass
```

### 4.3 导入顺序

1. 标准库导入
2. 第三方库导入
3. 本地应用导入

```python
# ✅ 正确
from pathlib import Path
from typing import Dict, Any
import json

from fastapi import APIRouter
import numpy as np

from core.config import settings
from data_parser.base_parser import BaseParser
```

### 4.4 错误处理

- 使用 `try-except` 进行错误处理
- 记录错误日志
- 抛出有意义的异常

```python
# ✅ 正确
try:
    data = parser.parse(file_path)
except Exception as e:
    logger.error(f"文件解析失败: {e}")
    raise HTTPException(status_code=500, detail=str(e))
```

### 4.5 日志记录

- 使用 `core.logging_config.logger` 记录日志
- 日志级别：DEBUG, INFO, WARNING, ERROR, CRITICAL

```python
from core.logging_config import logger

logger.info("文件上传成功")
logger.error(f"解析失败: {e}")
logger.warning("使用备用解析器")
```

## 五、架构设计原则

### 5.1 模块化设计

- 每个模块职责单一
- 使用抽象基类定义接口
- 使用工厂模式创建实例

### 5.2 依赖注入

- 配置通过 `core.config.settings` 统一管理
- 不要在模块中硬编码路径或配置

```python
# ✅ 正确
from core.config import settings
upload_dir = Path(settings.UPLOAD_DIR)

# ❌ 错误
upload_dir = Path("./uploads")
```

### 5.3 接口抽象

- 解析器继承 `BaseParser`
- 学习器继承 `BaseSchemaLearner`
- 新格式支持通过实现接口添加

### 5.4 AI集成

- LLM客户端支持多提供商（Ollama/LM Studio/OpenAI）
- 使用配置切换提供商，不硬编码
- 向量数据库支持FAISS和ChromaDB

## 六、文件格式支持

### 6.1 当前支持的格式

- ✅ XML (`.xml`)
- ✅ JSON (`.json`)
- ✅ YAML (`.yaml`, `.yml`)
- ✅ CSV (`.csv`)
- ✅ TSV (`.tsv`)
- ✅ Excel (`.xlsx`, `.xls`)

### 6.2 添加新格式

1. 在 `data_parser/` 创建新的解析器类
2. 继承 `BaseParser` 实现必需方法
3. 在 `parser_factory.py` 中注册

## 七、路径配置规则

### 7.1 路径规范

- **所有路径**统一配置在 `backend/core/config.py`
- 使用 `F:\StructForgeAI` 作为根目录
- 使用 `pathlib.Path` 处理路径，不使用字符串拼接

```python
# ✅ 正确
from pathlib import Path
file_path = Path(settings.UPLOAD_DIR) / filename

# ❌ 错误
file_path = settings.UPLOAD_DIR + "/" + filename
```

### 7.2 路径创建

- 使用 `mkdir(parents=True, exist_ok=True)` 创建目录
- 创建前检查父目录是否存在

## 八、API设计规范

### 8.1 RESTful API

- 使用标准HTTP方法：GET, POST, PUT, DELETE
- URL使用复数名词：`/api/v1/files`, `/api/v1/schemas`
- 使用适当的HTTP状态码

### 8.2 统一响应格式

#### 后端API响应格式

**成功响应**：使用 `api.base.AIWorkflowService.create_success_response()`
```python
from api.base import AIWorkflowService

return ai_service.create_success_response(
    message="操作完成",
    data={"analysis": result}  # 可选
)
# 返回: {"success": True, "message": "...", "data": {...}}
```

**错误响应**：使用 `api.base.AIWorkflowService.create_error_response()`
```python
raise ai_service.create_error_response(f"操作失败: {str(e)}")
# 抛出: HTTPException(status_code=500, detail="...")
```

#### 前端API调用规范

**响应拦截器**：`api.ts` 中的响应拦截器已返回 `response.data`，所以：
```typescript
// ✅ 正确：response 已经是响应体，不是 AxiosResponse
const response: any = await api.post('/endpoint', data)
return {
  success: response.success,
  data: response.data?.field || response.field,
  message: response.message,
}

// ❌ 错误：不要访问 response.data.data
const response = await api.post('/endpoint', data)
return response.data.data  // 错误！
```

### 8.3 AI节点API规范

**使用基类**：所有AI节点API必须使用 `AIWorkflowService`
```python
from api.base import AIWorkflowService

router = APIRouter()
ai_service = AIWorkflowService()

@router.post("/endpoint")
async def endpoint(request: RequestModel):
    result = await ai_service.call_ai(
        system_role="...",
        user_prompt="...",
        operation_name="操作名称"
    )
    return ai_service.create_success_response(
        message="完成",
        data={"result": result}
    )
```

### 8.4 API版本

- 使用URL版本控制：`/api/v1/`
- 新版本创建新的路由模块

## 九、测试规范

### 9.1 测试文件位置

- 单元测试：`tests/unit/`
- 集成测试：`tests/integration/`
- 测试文件命名：`test_*.py`

### 9.2 测试命名

- 测试函数：`test_<功能描述>()`
- 测试类：`Test<类名>`

## 十、Git提交规范

### 10.1 提交信息格式

```
<type>(<scope>): <subject>

<body>
```

**Type类型**：
- `feat`: 新功能
- `fix`: 修复bug
- `docs`: 文档更新
- `style`: 代码格式调整
- `refactor`: 重构
- `test`: 测试相关
- `chore`: 构建/工具相关

**示例**：
```
feat(parser): 添加Excel解析器支持

- 支持.xlsx和.xls格式
- 支持多Sheet解析
- 自动推断数据类型
```

## 十一、性能优化规范

### 11.1 RTX 4060优化

- 使用Q4量化模型（推荐Qwen2.5-7B）
- VRAM占用控制在6GB以内
- 使用异步处理大文件
- 缓存常见Schema分析结果

### 11.2 内存管理

- 大文件使用流式处理
- 及时释放不需要的对象
- 避免在内存中保存过多数据

## 十二、工作流节点扩展规范

### 12.1 添加新节点类型（后端）

1. **创建API端点**（`backend/api/`）
   ```python
   # backend/api/new_node.py
   from api.base import AIWorkflowService
   from fastapi import APIRouter
   from pydantic import BaseModel
   
   router = APIRouter()
   ai_service = AIWorkflowService()
   
   class NewNodeRequest(BaseModel):
       # 请求参数
       pass
   
   @router.post("/new-node")
   async def new_node(request: NewNodeRequest):
       # 使用 ai_service.call_ai() 或直接处理
       result = await ai_service.call_ai(...)
       return ai_service.create_success_response(
           message="完成",
           data={"result": result}
       )
   ```

2. **注册路由**（`backend/api/__init__.py`）
   ```python
   router.include_router(new_node.router, prefix="/new-node", tags=["新节点"])
   ```

### 12.2 添加新节点类型（前端）

1. **创建执行器**（`frontend/src/components/Workflow/NodeExecutors/`）
   ```typescript
   // NewNodeExecutor.ts
   import { BaseExecutor } from './BaseExecutor'
   import { newNodeApi } from '@/services/api'
   
   export class NewNodeExecutor extends BaseExecutor {
     async execute(): Promise<ExecutorResult> {
       // 实现执行逻辑
       const result = await newNodeApi.call(...)
       return { success: true, result }
     }
   }
   ```

2. **创建配置组件**（`frontend/src/components/Workflow/NodeConfigs/`）
   ```typescript
   // NewNodeConfig.tsx
   export const NewNodeConfig: React.FC<NodeConfigProps> = ({ form }) => {
     return (
       <Form.Item name="param" label="参数">
         <Input />
       </Form.Item>
     )
   }
   ```

3. **注册执行器和配置**
   - 在 `NodeExecutors/index.ts` 注册执行器
   - 在 `NodeConfigs/index.tsx` 注册配置组件
   - 在 `WorkflowNode.tsx` 添加节点类型和验证逻辑

4. **更新类型定义**
   - 在 `WorkflowNode.tsx` 的 `NodeType` 中添加新类型
   - 在 `WorkflowEditor.tsx` 的 `defaultNodeConfigs` 中添加默认配置

### 12.3 节点类型分类

- **基础节点**：`parse_file`, `analyze_schema`, `export_file`
- **数据处理节点**：`edit_data`, `filter_data`, `validate_data`
- **AI智能节点**：`analyze_xml_structure`, `generate_editor_config`, `smart_edit`, `generate_workflow`
- **传统节点**：`process_natural_language`, `apply_operations`

## 十三、存储系统规范

### 13.1 存储后端选择

支持多种存储后端（通过 `WORKFLOW_STORAGE_TYPE` 配置）：
- `memory` - 内存存储（开发/测试）
- `json` - JSON文件存储（小项目）
- `sqlite` - SQLite数据库（推荐用于中小项目）
- `postgresql` - PostgreSQL（大型项目）
- `mysql` - MySQL（大型项目）

### 13.2 存储接口规范

所有存储实现必须继承 `storage.base.WorkflowStorage`：
```python
from storage.base import WorkflowStorage

class CustomStorage(WorkflowStorage):
    async def save(self, workflow_id: str, workflow_data: Dict) -> None:
        # 实现保存逻辑
        pass
    
    async def load(self, workflow_id: str) -> Dict:
        # 实现加载逻辑
        pass
    # ... 实现其他必需方法
```

### 13.3 数据迁移

使用 `storage.migrate.StorageMigrator` 进行存储迁移：
```python
from storage.migrate import StorageMigrator

migrator = StorageMigrator()
await migrator.migrate(source_storage, target_storage)
```

## 十四、代码审查检查清单

编写代码时确保：
- [ ] 遵循命名规范（类PascalCase，函数snake_case）
- [ ] 添加类型提示（Python）或类型定义（TypeScript）
- [ ] 添加docstring（Python）或JSDoc（TypeScript）
- [ ] 使用logger记录日志（后端）
- [ ] 错误处理完善
- [ ] 路径使用pathlib.Path（Python）
- [ ] 配置通过settings获取
- [ ] API路由使用kebab-case
- [ ] 代码格式符合PEP 8（Python）或ESLint（TypeScript）
- [ ] 新节点使用模块化架构（NodeExecutors + NodeConfigs）
- [ ] AI节点API使用 `AIWorkflowService` 基类
- [ ] 统一使用 `create_success_response()` 和 `create_error_response()`

## 十五、特殊约定

### 15.1 AI模型

- 默认模型：Qwen2.5-7B-Instruct (Q4量化)
- 提供商优先级：Ollama > LM Studio > OpenAI
- 支持本地部署优先，保护数据隐私

### 15.2 文件处理

- 上传文件保存在 `data/uploads/`
- 导出文件保存在 `data/exports/`
- 支持的文件大小限制：默认100MB

### 15.3 日志文件

- 日志保存在 `logs/` 目录
- 日志文件不提交到Git
- 使用轮转避免日志文件过大

### 15.4 前端状态管理

- 使用 React Hooks (`useState`, `useEffect`, `useCallback`)
- 工作流状态通过 `useNodesState` 和 `useEdgesState` 管理
- 节点配置和执行结果通过 `NodeDetailPanel` 管理

### 15.5 模块化架构原则

**前端节点架构**：
- ✅ 每个节点类型有独立的执行器（`NodeExecutors/`）
- ✅ 每个节点类型有独立的配置组件（`NodeConfigs/`）
- ✅ 通过注册表统一管理，便于扩展
- ❌ 不要在主文件中写所有节点的配置和执行逻辑

**后端API架构**：
- ✅ AI节点使用 `AIWorkflowService` 基类
- ✅ 统一使用 `create_success_response()` 和 `create_error_response()`
- ✅ 公共逻辑提取到 `api.base` 模块
- ❌ 不要在多个端点中重复AI调用和JSON解析代码

---

**遵循这些规范确保代码质量和项目一致性！**
